{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# Japanese font installation\n",
    "# 1) `$ mkdir $HOME/.fonts`\n",
    "# 2) Download Osaka.ttf tp $HOME/.fonts/\n",
    "# 3) `$ fc-cache`\n",
    "# 4) (optional) Clear matplotlib cache dir, find the dir with `matplotlib.get_cachedir()`\n",
    "plt.rcParams['font.family'] = 'Osaka'\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phiradet/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Checkpoint directory ./logs exists and is not empty. With save_top_k=5, all files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/Users/phiradet/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | content_id_emb | Embedding | 3 M   \n",
      "1 | bundle_id_emb  | Embedding | 1 M   \n",
      "2 | lstm           | LSTM      | 1 M   \n",
      "3 | hidden2logit   | Linear    | 257   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor(\n",
      "  (content_id_emb): Embedding(13942, 256, padding_idx=0)\n",
      "  (bundle_id_emb): Embedding(9767, 128, padding_idx=0)\n",
      "  (lstm): LSTM(588, 256, num_layers=2, batch_first=True, dropout=0.3)\n",
      "  (hidden2logit): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "total param: 6,212,225\n",
      "total param: 6,212,225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3f0fdbcba8454ea4c77034056880be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from libs.dataset import RiidDataset, get_data_loader\n",
    "from libs.model import Predictor\n",
    "\n",
    "import pickle\n",
    "\n",
    "dataset = RiidDataset(data_root_dir=\"../dataset/processed\", split=\"train\")\n",
    "\n",
    "dataloader = get_data_loader(dataset=dataset, batch_size=16,\n",
    "                             shuffle=False, num_workers=8)\n",
    "\n",
    "bundle_id_idx = pickle.load(open(\"../dataset/processed/indexes/bundle_id_idx.pickle\", \"rb\"))\n",
    "part_idx = pickle.load(open(\"../dataset/processed/indexes/part_idx.pickle\", \"rb\"))\n",
    "content_id_idx = pickle.load(open(\"../dataset/processed/indexes/content_id_idx.pickle\", \"rb\"))\n",
    "type_idx = pickle.load(open(\"../dataset/processed/indexes/type_idx.pickle\", \"rb\"))\n",
    "\n",
    "\n",
    "config = dict(content_id_size=len(content_id_idx)+1,\n",
    "              content_id_dim=256,\n",
    "              bundle_id_size=len(bundle_id_idx)+1,\n",
    "              bundle_id_dim=128,\n",
    "              feature_dim=204,\n",
    "              lstm_hidden_dim=256,\n",
    "              lstm_num_layers=2,\n",
    "              lstm_dropout=0.3,\n",
    "              emb_dropout=0.3,\n",
    "              output_dropout=0.3,\n",
    "              lr=0.05)\n",
    "# config = dict(content_id_size=len(content_id_idx)+1,\n",
    "#               content_id_dim=8,\n",
    "#               bundle_id_size=len(bundle_id_idx)+1,\n",
    "#               bundle_id_dim=8,\n",
    "#               feature_dim=204,\n",
    "#               lstm_hidden_dim=8,\n",
    "#               lstm_num_layers=1,\n",
    "#               lstm_dropout=0.3,\n",
    "#               emb_dropout=0.3,\n",
    "#               output_dropout=0.3,\n",
    "#               lr=0.001)\n",
    "\n",
    "model = Predictor(**config)\n",
    "print(model)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"total param: {total_params:,}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"total learnable param: {total_params:,}\")\n",
    "\n",
    "save_top_k = 5\n",
    "max_epochs = 1\n",
    "train_loader = dataloader\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='train_loss',\n",
    "    dirpath='./logs',\n",
    "    save_top_k=save_top_k,\n",
    "    mode='min')\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=\"./tensorboard_logs\", name='riid')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     callbacks=[checkpoint_callback],\n",
    "                     logger=logger)\n",
    "trainer.fit(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
